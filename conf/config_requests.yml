task: 'requests'

hf_cache_dir: '/srv/data/egasj/hf_cache/'
#hf_cache_dir: '/home/user/Documents/hf_cache/'
#hf_cache_dir: '/media/jvel/data/hf_cache/'

pretrained_model_details:
#  checkpoint_path: 'openai/whisper-small'
  checkpoint_path: 'openai/whisper-large'

paths:
#  to_labels: 'data/requests/labels_local.csv' # jvel PC
  to_csv: 'data/metadata/' # deep 4
  to_save_transcripts: 'data/transcripts/'
#  audio_path: '/media/jvel/data/audio/DEPISDA_16k'
  audio_path: '/srv/data/egasj/corpora/requests'
#  audio_path: '/home/user/Documents/corpora/requests'
  out_embeddings: 'data/embeddings/'
  output_results: 'data/results/experiments.csv'

feature_combination: False
sampling_rate: 16000
# This is read from ../sclerosis_multiple.py
discrimination:
  emb_type: 'hiddens'
#  emb_type: 'convs'
shuffle_data: True
# data preprocessing
dimension_reduction:
  method: None #'vae'  # pca, autoencoder (basic), vae (variational autoencoder)
  pca:
    # best n_components = 193 (0.95); 302 (0.97) ==> hiddens;
    # best n_components = 79 (0.95); 118 (0.97) ==> convs;
    n_components: 0.95  # first 4 => 0.97
    save_pca: False
#    pca_path: "data/bea-base-train-flat/dim_red/bea_train_flat_pca" #.pkl
    pca_path: "data/bea-base-train-flat/dim_red/bea_train_flat_pca_comb" #.pkl
  autoencoder:
    encoder_size: 471 # akin to n_components for the autoencoder  #178 fpr convs; 471 hiddens
    num_epochs: 15000
    save_path: "data/bea-base-train-flat/dim_red/autoencoder/bea_train_flat"

data_scaling:
  save_scaling_model: False
#  scaling_model_path: "data/bea-base-train-flat/dim_red/train_flat" #.pkl
  scaling_model_path: "data/bea-base-train-flat/dim_red/compare_func_xv" #.pkl
   # "minmax" "standard" "robust" "normalizer" null
  scaler_type: "robust"
